{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from io import StringIO\n",
    "setattr(pd, \"Int64Index\", pd.Index)\n",
    "setattr(pd, \"Float64Index\", pd.Index)\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express\n",
    "from arrow import now\n",
    "from flaml import AutoML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from flaml import AutoML, tune\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data/drug_consumption.csv\"\n",
    "file_path = os.path.join(os.getcwd(), file_name)  \n",
    "df = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a folder to store all of the trained models from the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if not os.path.exists('trained_models'):\n",
    "            os.makedirs('trained_models')\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
      "0   1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
      "1   2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
      "2   3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
      "3   4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
      "4   5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
      "\n",
      "    Oscore   Ascore  ...  Ecstasy  Heroin  Ketamine Legalh  LSD Meth  \\\n",
      "0 -0.58331 -0.91699  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
      "1  1.43533  0.76096  ...      CL4     CL0       CL2    CL0  CL2  CL3   \n",
      "2 -0.84732 -1.62090  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
      "3 -0.01928  0.59042  ...      CL0     CL0       CL2    CL0  CL0  CL0   \n",
      "4 -0.45174 -0.30172  ...      CL1     CL0       CL0    CL1  CL0  CL0   \n",
      "\n",
      "  Mushrooms Nicotine Semer  VSA  \n",
      "0       CL0      CL2   CL0  CL0  \n",
      "1       CL0      CL4   CL0  CL0  \n",
      "2       CL1      CL0   CL0  CL0  \n",
      "3       CL0      CL2   CL0  CL0  \n",
      "4       CL2      CL2   CL0  CL0  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "<bound method NDFrame.describe of         ID      Age   Gender  Education  Country  Ethnicity   Nscore   Escore  \\\n",
      "0        1  0.49788  0.48246   -0.05921  0.96082    0.12600  0.31287 -0.57545   \n",
      "1        2 -0.07854 -0.48246    1.98437  0.96082   -0.31685 -0.67825  1.93886   \n",
      "2        3  0.49788 -0.48246   -0.05921  0.96082   -0.31685 -0.46725  0.80523   \n",
      "3        4 -0.95197  0.48246    1.16365  0.96082   -0.31685 -0.14882 -0.80615   \n",
      "4        5  0.49788  0.48246    1.98437  0.96082   -0.31685  0.73545 -1.63340   \n",
      "...    ...      ...      ...        ...      ...        ...      ...      ...   \n",
      "1880  1884 -0.95197  0.48246   -0.61113 -0.57009   -0.31685 -1.19430  1.74091   \n",
      "1881  1885 -0.95197 -0.48246   -0.61113 -0.57009   -0.31685 -0.24649  1.74091   \n",
      "1882  1886 -0.07854  0.48246    0.45468 -0.57009   -0.31685  1.13281 -1.37639   \n",
      "1883  1887 -0.95197  0.48246   -0.61113 -0.57009   -0.31685  0.91093 -1.92173   \n",
      "1884  1888 -0.95197 -0.48246   -0.61113  0.21128   -0.31685 -0.46725  2.12700   \n",
      "\n",
      "       Oscore   Ascore  ...  Ecstasy  Heroin  Ketamine Legalh  LSD Meth  \\\n",
      "0    -0.58331 -0.91699  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
      "1     1.43533  0.76096  ...      CL4     CL0       CL2    CL0  CL2  CL3   \n",
      "2    -0.84732 -1.62090  ...      CL0     CL0       CL0    CL0  CL0  CL0   \n",
      "3    -0.01928  0.59042  ...      CL0     CL0       CL2    CL0  CL0  CL0   \n",
      "4    -0.45174 -0.30172  ...      CL1     CL0       CL0    CL1  CL0  CL0   \n",
      "...       ...      ...  ...      ...     ...       ...    ...  ...  ...   \n",
      "1880  1.88511  0.76096  ...      CL0     CL0       CL0    CL3  CL3  CL0   \n",
      "1881  0.58331  0.76096  ...      CL2     CL0       CL0    CL3  CL5  CL4   \n",
      "1882 -1.27553 -1.77200  ...      CL4     CL0       CL2    CL0  CL2  CL0   \n",
      "1883  0.29338 -1.62090  ...      CL3     CL0       CL0    CL3  CL3  CL0   \n",
      "1884  1.65653  1.11406  ...      CL3     CL0       CL0    CL3  CL3  CL0   \n",
      "\n",
      "     Mushrooms Nicotine Semer  VSA  \n",
      "0          CL0      CL2   CL0  CL0  \n",
      "1          CL0      CL4   CL0  CL0  \n",
      "2          CL1      CL0   CL0  CL0  \n",
      "3          CL0      CL2   CL0  CL0  \n",
      "4          CL2      CL2   CL0  CL0  \n",
      "...        ...      ...   ...  ...  \n",
      "1880       CL0      CL0   CL0  CL5  \n",
      "1881       CL4      CL5   CL0  CL0  \n",
      "1882       CL2      CL6   CL0  CL0  \n",
      "1883       CL3      CL4   CL0  CL0  \n",
      "1884       CL3      CL6   CL0  CL2  \n",
      "\n",
      "[1885 rows x 32 columns]>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1885 entries, 0 to 1884\n",
      "Data columns (total 32 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   ID         1885 non-null   int64  \n",
      " 1   Age        1885 non-null   float64\n",
      " 2   Gender     1885 non-null   float64\n",
      " 3   Education  1885 non-null   float64\n",
      " 4   Country    1885 non-null   float64\n",
      " 5   Ethnicity  1885 non-null   float64\n",
      " 6   Nscore     1885 non-null   float64\n",
      " 7   Escore     1885 non-null   float64\n",
      " 8   Oscore     1885 non-null   float64\n",
      " 9   Ascore     1885 non-null   float64\n",
      " 10  Cscore     1885 non-null   float64\n",
      " 11  Impulsive  1885 non-null   float64\n",
      " 12  SS         1885 non-null   float64\n",
      " 13  Alcohol    1885 non-null   object \n",
      " 14  Amphet     1885 non-null   object \n",
      " 15  Amyl       1885 non-null   object \n",
      " 16  Benzos     1885 non-null   object \n",
      " 17  Caff       1885 non-null   object \n",
      " 18  Cannabis   1885 non-null   object \n",
      " 19  Choc       1885 non-null   object \n",
      " 20  Coke       1885 non-null   object \n",
      " 21  Crack      1885 non-null   object \n",
      " 22  Ecstasy    1885 non-null   object \n",
      " 23  Heroin     1885 non-null   object \n",
      " 24  Ketamine   1885 non-null   object \n",
      " 25  Legalh     1885 non-null   object \n",
      " 26  LSD        1885 non-null   object \n",
      " 27  Meth       1885 non-null   object \n",
      " 28  Mushrooms  1885 non-null   object \n",
      " 29  Nicotine   1885 non-null   object \n",
      " 30  Semer      1885 non-null   object \n",
      " 31  VSA        1885 non-null   object \n",
      "dtypes: float64(12), int64(1), object(19)\n",
      "memory usage: 471.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.describe) #(1885, 32)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the columns to categorical and numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "       # Numeric columns \n",
    "       'ID', 'Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Nscore',\n",
    "       'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS',\n",
    "       # Categoriocal Columns\n",
    "       'Alcohol','Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', \n",
    "       'Crack','Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms',\n",
    "       'Nicotine', 'Semer', 'VSA']\n",
    "\n",
    "float_columns =  ['Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Nscore',\n",
    "                  'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS',]\n",
    "\n",
    "# we do not have enough positives for Semer to be meaningful so we're going to have to leave it out\n",
    "targets = ['Alcohol', 'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack', 'Ecstasy',\n",
    "           'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'Nicotine', 'Semer', 'VSA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding for tree based classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "for cat in targets:\n",
    "    df[cat] = label_encoder.fit_transform(df[cat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a small dataset the time to train each model is small as well, you should not need more than 1 second to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 04-01 16:17:38] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 04-01 16:17:38] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 04-01 16:17:38] {1789} INFO - Minimizing error metric: mse\n",
      "[flaml.automl.logger: 04-01 16:17:38] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
      "[flaml.automl.logger: 04-01 16:17:38] {2219} INFO - iteration 0, current learner lgbm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m automl_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_budget\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# In seconds\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_file_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmylog.log\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# fit classification on the training data\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mautoml_settings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Export the best model\u001b[39;00m\n\u001b[1;32m     21\u001b[0m retrained_model \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/automl.py:1926\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X_train, y_train, dataframe, label, metric, task, n_jobs, log_file_name, estimator_list, time_budget, max_iter, sample, ensemble, eval_method, log_type, model_history, split_ratio, n_splits, log_training_metric, mem_thres, pred_time_limit, train_time_limit, X_val, y_val, sample_weight_val, groups_val, groups, verbose, retrain_full, split_type, learner_selector, hpo_method, starting_points, seed, n_concurrent_trials, keep_search_state, preserve_checkpoint, early_stop, force_cancel, append_log, auto_augment, min_sample_size, use_ray, use_spark, free_mem_ratio, metric_constraints, custom_hp, time_col, cv_score_agg_func, skip_transform, mlflow_logging, fit_kwargs_by_estimator, **fit_kwargs)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m training_log_writer(log_file_name, append_log) \u001b[38;5;28;01mas\u001b[39;00m save_helper:\n\u001b[1;32m   1925\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m save_helper\n\u001b[0;32m-> 1926\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_training_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/automl.py:2483\u001b[0m, in \u001b[0;36mAutoML._search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2481\u001b[0m     state\u001b[38;5;241m.\u001b[39mbest_config \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39minit_config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39minit_config \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_ray \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_spark \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m-> 2483\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_search_sequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_search_parallel()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/automl.py:2319\u001b[0m, in \u001b[0;36mAutoML._search_sequential\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2313\u001b[0m         search_state\u001b[38;5;241m.\u001b[39msearch_alg\u001b[38;5;241m.\u001b[39msearcher\u001b[38;5;241m.\u001b[39mset_search_properties(\n\u001b[1;32m   2314\u001b[0m             metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2315\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2316\u001b[0m             metric_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mbest_loss,\n\u001b[1;32m   2317\u001b[0m         )\n\u001b[1;32m   2318\u001b[0m start_run_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 2319\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_alg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_alg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_budget_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_budget_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_spark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2327\u001b[0m time_used \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_run_time\n\u001b[1;32m   2328\u001b[0m better \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/tune/tune.py:814\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(evaluation_function, config, low_cost_partial_config, cat_hp_cost, metric, mode, time_budget_s, points_to_evaluate, evaluated_rewards, resource_attr, min_resource, max_resource, reduction_factor, scheduler, search_alg, verbose, local_dir, num_samples, resources_per_trial, config_constraints, metric_constraints, max_failure, use_ray, use_spark, use_incumbent_result_in_evaluation, log_file_name, lexico_objectives, force_cancel, n_concurrent_trials, **ray_args)\u001b[0m\n\u001b[1;32m    812\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PySparkOvertimeMonitor(time_start, time_budget_s, force_cancel):\n\u001b[0;32m--> 814\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_to_run\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/state.py:304\u001b[0m, in \u001b[0;36mAutoMLState._compute_with_config_base\u001b[0;34m(config_w_resource, state, estimator, is_report)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLAML_sample_size\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    290\u001b[0m budget \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (state\u001b[38;5;241m.\u001b[39mtime_budget \u001b[38;5;241m-\u001b[39m state\u001b[38;5;241m.\u001b[39mtime_from_start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sample_size \u001b[38;5;241m/\u001b[39m state\u001b[38;5;241m.\u001b[39mdata_size[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    296\u001b[0m )\n\u001b[1;32m    298\u001b[0m (\n\u001b[1;32m    299\u001b[0m     trained_estimator,\n\u001b[1;32m    300\u001b[0m     val_loss,\n\u001b[1;32m    301\u001b[0m     metric_for_logging,\n\u001b[1;32m    302\u001b[0m     _,\n\u001b[1;32m    303\u001b[0m     pred_time,\n\u001b[0;32m--> 304\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_X_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43msampled_y_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_time_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearner_classes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_score_agg_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_estimator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mretrain_final \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state\u001b[38;5;241m.\u001b[39mmodel_history:\n\u001b[1;32m    327\u001b[0m     trained_estimator\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/ml.py:351\u001b[0m, in \u001b[0;36mcompute_estimator\u001b[0;34m(X_train, y_train, X_val, y_val, weight_val, groups_val, budget, kf, config_dic, task, estimator_name, eval_method, eval_metric, best_val_loss, n_jobs, estimator_class, cv_score_agg_func, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    348\u001b[0m     fit_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m y_val\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mholdout\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m==\u001b[39m eval_method:\n\u001b[0;32m--> 351\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m \u001b[43mget_val_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_dic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel_list\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass the label list on to compute the evaluation metric\u001b[39;49;00m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_training_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_training_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     val_loss, metric_for_logging, train_time, pred_time \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mevaluate_model_CV(\n\u001b[1;32m    370\u001b[0m         config_dic,\n\u001b[1;32m    371\u001b[0m         estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m         free_mem_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    382\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/ml.py:494\u001b[0m, in \u001b[0;36mget_val_loss\u001b[0;34m(config, estimator, X_train, y_train, X_val, y_val, weight_val, groups_val, eval_metric, task, labels, budget, log_training_metric, fit_kwargs, free_mem_ratio)\u001b[0m\n\u001b[1;32m    489\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['groups_val'] = groups_val\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['X_val'] = X_val\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m#     fit_kwargs['y_val'] = y_val\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfree_mem_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m val_loss, metric_for_logging, pred_time, _ \u001b[38;5;241m=\u001b[39m _eval_estimator(\n\u001b[1;32m    496\u001b[0m     config,\n\u001b[1;32m    497\u001b[0m     estimator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    508\u001b[0m     fit_kwargs,\n\u001b[1;32m    509\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(estimator, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/model.py:1413\u001b[0m, in \u001b[0;36mLGBMEstimator.fit\u001b[0;34m(self, X_train, y_train, budget, free_mem_ratio, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m   1412\u001b[0m         callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1415\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1420\u001b[0m     \u001b[38;5;66;03m# for xgboost>=1.6.0, pop callbacks to enable pickle\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/flaml/automl/model.py:220\u001b[0m, in \u001b[0;36mBaseEstimator._fit\u001b[0;34m(self, X_train, y_train, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;66;03m# groups_val = kwargs.get('groups_val')\u001b[39;00m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;66;03m# if groups_val is not None:\u001b[39;00m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m#     kwargs['eval_group'] = [group_counts(groups_val)]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m#     kwargs['verbose'] = False\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;66;03m#     del kwargs['groups_val'], kwargs['X_val'], kwargs['y_val']\u001b[39;00m\n\u001b[1;32m    219\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess(X_train)\n\u001b[0;32m--> 220\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# xgboost 1.6 doesn't display all the params in the model str\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflaml.automl.model - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fit started with params \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "# Store each model of the target variable into a dictionary\n",
    "model_output = {}\n",
    "\n",
    "#auto_ml(df, targets)\n",
    "for target in targets:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[float_columns], df[target], test_size=0.20, random_state=2024)\n",
    "\n",
    "    automl = AutoML()\n",
    "\n",
    "    automl_settings = {\n",
    "        \"time_budget\": 1,  # In seconds\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"task\": \"classification\",\n",
    "        \"log_file_name\": 'mylog.log',\n",
    "    }\n",
    "\n",
    "    # fit classification on the training data\n",
    "    clf = automl.fit(X_train=X_train, y_train=y_train, **automl_settings)\n",
    "\n",
    "    # Export the best model\n",
    "    retrained_model = automl.model\n",
    "    print(automl.model)\n",
    "\n",
    "    model_output[target] = retrained_model.estimator\n",
    "    \n",
    "    # Save the model to a file\n",
    "    with open(f'./trained_models/{target}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(retrained_model.estimator, f)\n",
    "\n",
    "    # Load the model from the file\n",
    "    with open(f'./trained_models/{target}_model.pkl', 'rb') as f:\n",
    "        retrained_model = pickle.load(f)\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_start = now()\n",
    "\n",
    "# Make sure that you have the same split as which the models were trained on\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[float_columns], df[target], test_size=0.20, random_state=2024)\n",
    "\n",
    "accuracy_results = {}\n",
    "f1_results = {}\n",
    "\n",
    "for target in targets:\n",
    "    model = model_output[target].fit(X=X_train, y=y_train)\n",
    "    f1_results[target] = f1_score(y_true=y_test, y_pred=model.predict(X_test), average='weighted')\n",
    "    accuracy_results[target] = accuracy_score(y_true=y_test, y_pred=model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_results)\n",
    "print(f1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(f1_results.keys())\n",
    "f1_score_results = list(f1_results.values())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(label, f1_score_results)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('f1-score')\n",
    "plt.title('F1-Scores for each Drug')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
